# ğŸ¤– GraphMind API â€“ AI Chat with LangGraph + FastAPI

https://graphmind-api.onrender.com -- Access it here.

An open-source beginner-friendly AI chat project using **LangGraph**, **FastAPI**, and **OpenRouter (free GPT/OpenAI alternatives)**.

![GraphMind Banner](assets/banner.png)

---

## ğŸš€ Features

- ğŸŒ Built with **FastAPI** â€“ Fast, simple web API
- ğŸ§  Uses **LangGraph** â€“ Graph-based LLM orchestration
- ğŸ”‘ Uses `.env` for API keys securely
- ğŸ”Œ Plug-and-play OpenRouter model support
- ğŸ—‚ï¸ Beginner-friendly project structure
- âš¡ Async-ready, production-extensible
- ğŸ“„ Swagger docs available at `/docs`

---

## ğŸ—‚ï¸ Project Structure

```
graphmind-api/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ flow.py        # LangGraph state graph setup
â”‚   â”œâ”€â”€ nodes.py       # LLM + Response generation logic
â”‚   â”œâ”€â”€ state.py       # Pydantic state definition
â”‚
â”œâ”€â”€ main.py            # FastAPI app entry point
â”œâ”€â”€ .env               # ğŸ” API keys and secrets (not committed)
â”œâ”€â”€ .gitignore         # Git ignored files
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md          # Youâ€™re here
```
![Flow Diagram](./app/asset/images/flow.png)
---

## ğŸ§© Prerequisites

- Python 3.10 or above
- pip
- Optional: Virtualenv

---

## âš™ï¸ Setup Instructions

### 1. Clone the project
```bash
git clone https://github.com/your-username/graphmind-api.git
cd graphmind-api
```

### 2. Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Create `.env` file
```env
OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## â–¶ï¸ Run the Project

```bash
uvicorn main:app --reload --port 8015
python3 -m uvicorn main:app --reload --port 8015
```

Visit ğŸ‘‰ http://127.0.0.1:8011/docs to try out the `/chat` API!

---

## ğŸ§ª Example API Usage

**Endpoint**:
```http
POST /chat?user_input=hello
```

**Response**:
```json
{
  "response": "Hi! How can I assist you today?"
}
```

---

## ğŸ“¸ Screenshots

### ğŸ”¹ Swagger UI (`/docs`)
![Swagger UI Screenshot](assets/swagger-ui.png)

### ğŸ”¹ Terminal Output
![Terminal Screenshot](assets/terminal.png)

---

## ğŸ’¬ Supported Models via OpenRouter

You can use any of the free or cheap models:
- `deepseek/deepseek-r1-0528:free` âœ… (Free!)
- `google/gemini-pro`
- `openai/gpt-3.5-turbo`
- And many more from https://openrouter.ai/models

---

## ğŸ‘¥ Contributing

Contributions welcome! Open issues, suggest features, or send pull requests.

---

## ğŸ“„ License

MIT License Â© 2025 [Your Name]

---

## ğŸ™ Acknowledgements

- [LangGraph](https://github.com/langchain-ai/langgraph)
- [FastAPI](https://fastapi.tiangolo.com)
- [OpenRouter](https://openrouter.ai)
- [LangChain](https://github.com/langchain-ai/langchain)

---

ğŸ§  *â€œFrom zero to graph-based AI with LangGraph. Letâ€™s build!â€*

# ğŸ¤– GraphMind API

A beginner-friendly FastAPI project using **LangGraph**, **OpenRouter**, and **LangChain** to build an intelligent conversational API with support for Open Source LLMs like DeepSeek.

---

## ğŸ“Œ Features

* ğŸ’¬ Conversational chat endpoint (`/chat?user_input=Hello`)
* ğŸ§  LangGraph-powered state machine to manage conversation flow
* ğŸ”“ Uses Open Source & Free LLMs via OpenRouter
* âœ… Secure key management with `.env`
* ğŸ›¡ï¸ GitHub Push Protection integrated

---

## ğŸ“ Project Structure

```bash
graphmind-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ nodes.py        # LLM logic (uses OpenRouter)
â”‚   â””â”€â”€ state.py        # Shared graph state (chat history)
â”œâ”€â”€ main.py             # FastAPI app with /chat endpoint
â”œâ”€â”€ .env                # Secret key (not committed)
â”œâ”€â”€ .gitignore          # Protects secrets & virtualenv
â”œâ”€â”€ README.md           # This file
â””â”€â”€ assets/             # Diagrams & screenshots
```

---

## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/graphmind-api.git
cd graphmind-api
```

### 2. Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Setup Environment Variables

Create a `.env` file:

```env
OPENROUTER_API_KEY=your-key-here
```

### 5. Run the Server

```bash
uvicorn main:app --reload
```

Visit: `http://127.0.0.1:8000/docs` to try the `/chat` endpoint.

---


## ğŸ”„ Code Flow Explained

### 1. `main.py`

* Starts a FastAPI app
* Builds a LangGraph from `generate_response`
* Calls `graph.invoke()` with user input

```python
@app.post("/chat")
def chat(user_input: str):
    state = GraphState(messages=[{"role": "user", "content": user_input}])
    final_state = graph.invoke(state)
    return {"response": final_state.messages[-1]["content"]}
```

### 2. `app/state.py`

Defines the state type that moves across graph steps.

```python
class GraphState(TypedDict):
    messages: list[dict]  # Chat history
```

### 3. `app/nodes.py`

Initializes the LLM client using OpenRouter.

```python
llm = ChatOpenAI(
    model="deepseek-chat",
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)

def generate_response(state: GraphState) -> GraphState:
    messages = state["messages"]
    response = llm.invoke(messages)
    messages.append({"role": "assistant", "content": response.content})
    return {"messages": messages}
```

### 4. LangGraph Setup

```python
builder = Graph()
builder.add_node("chat", generate_response)
builder.set_entry_point("chat")
graph = builder.compile()
```

---

## ğŸ“Š Visual Flow

> Add to README:

**High-Level:**

```
User Input â” /chat Endpoint â” GraphState â” LangGraph Node â” OpenRouter LLM â” Assistant Reply
```

**Low-Level:**

```
FastAPI
    â””â”€ GET /chat
        â””â”€ Create GraphState
            â””â”€ LangGraph.invoke()
                â””â”€ generate_response()
                    â””â”€ ChatOpenAI (via OpenRouter)
                        â””â”€ Returns response
```

---

## ğŸ“¦ Tech Stack

* **FastAPI** - REST API Framework
* **LangGraph** - Graph-based LLM orchestrator
* **LangChain** - Abstraction layer for LLMs
* **OpenRouter** - API gateway for multiple free and open-source LLMs
* **DeepSeek** - Free, high-quality open LLM

---

## ğŸ” Security & Best Practices

* API keys stored in `.env` (never hard-coded)
* `.gitignore` prevents leaking `.env` & `venv`
* GitHub Push Protection blocks secrets
